{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "import data\n",
    "import model\n",
    "import preprocessing\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = utils.yaml_to_dict('config.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer paso: preprocesar los datos \n",
    "Hacerlo solo una vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [......................................................................] 178002169 / 178002169"
     ]
    }
   ],
   "source": [
    "preprocessing.download_data(params)\n",
    "preprocessing.extract_data(params)\n",
    "preprocessing.generate_spectogram_images(params)\n",
    "preprocessing.make_id_label_map(params)\n",
    "preprocessing.split_data(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segund Paso: instanciar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 112, 112, 64)      9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 192)       110784    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 56, 56, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 56, 56, 192)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 28, 28, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 192)       331968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 192)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1930      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 455,946\n",
      "Trainable params: 455,050\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(224,224, 3))\n",
    "net = model.ModelArchitecture(num_classes=params['num_classes'])\n",
    "x = net(inputs, training=False)\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tercer paso: crear el generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 683 images.\n"
     ]
    }
   ],
   "source": [
    "generator = data.make_datagenerator(params, mode='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuarto paso: correr el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "270/270 [==============================] - 16s 60ms/step - loss: 2.3037 - acc: 0.1054\n",
      "Epoch 2/10\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 2.3013 - acc: 0.1178 3s  - ETA: 0s - loss: 2.3009 - a\n",
      "Epoch 3/10\n",
      "270/270 [==============================] - 14s 51ms/step - loss: 2.3008 - acc: 0.1109\n",
      "Epoch 4/10\n",
      "270/270 [==============================] - 14s 52ms/step - loss: 2.3008 - acc: 0.1170\n",
      "Epoch 5/10\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 2.3008 - acc: 0.1109\n",
      "Epoch 6/10\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 2.3003 - acc: 0.1153 0s - loss: 2.3004 - acc: 0\n",
      "Epoch 7/10\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 2.3001 - acc: 0.1160\n",
      "Epoch 8/10\n",
      "270/270 [==============================] - 11s 41ms/step - loss: 2.3007 - acc: 0.1081\n",
      "Epoch 9/10\n",
      "270/270 [==============================] - 12s 46ms/step - loss: 2.2997 - acc: 0.1168\n",
      "Epoch 10/10\n",
      "270/270 [==============================] - 13s 48ms/step - loss: 2.2999 - acc: 0.1212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x237e6e3d828>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "net.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "net.fit_generator(generator, steps_per_epoch=270, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\PC\\Anaconda3\\envs\\TensorFlow-GPU-Keras\\lib\\site-packages\\pydub\\utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "import data\n",
    "import model\n",
    "import preprocessing\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = utils.yaml_to_dict('config.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer paso: preprocesar los datos \n",
    "Hacerlo solo una vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size is bigger than record segment: specgram_matrix_S-acelera11_segment24.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-acelera4_segment0.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-acelera5_segment11.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-acelera6_segment15.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-acelera7_segment16.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-acelera8_segment0.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-acelera8_segment1.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-arranca8_segment0.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-avanza9_segment22.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-frena10_segment24.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-frena5_segment28.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-izquierda7_segment6.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-izquierda9_segment25.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede11_segment6.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede11_segment14.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede11_segment16.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede11_segment26.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede4_segment0.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede5_segment0.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede8_segment0.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede8_segment2.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede8_segment3.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede8_segment5.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede8_segment6.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede8_segment11.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede8_segment13.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede8_segment14.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede8_segment15.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede8_segment17.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede8_segment21.jpg\n",
      "Window size is bigger than record segment: specgram_matrix_S-retrocede8_segment23.jpg\n"
     ]
    }
   ],
   "source": [
    "preprocessing.download_data(params)\n",
    "preprocessing.extract_data(params)\n",
    "preprocessing.generate_spectogram_images(params)\n",
    "preprocessing.make_id_label_map(params)\n",
    "preprocessing.split_data(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segund Paso: instanciar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 112, 112, 64)      9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 192)       110784    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 56, 56, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 56, 56, 192)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 28, 28, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 192)       331968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 192)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1930      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 455,946\n",
      "Trainable params: 455,050\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(224,224, 3))\n",
    "net = model.ModelArchitecture(num_classes=params['num_classes'])\n",
    "x = net(inputs, training=False)\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tercer paso: crear el generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2416 images.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2416"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = data.make_datagenerator(params, mode='training')\n",
    "generator.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuarto paso: correr el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "241/241 [==============================] - 8s 31ms/step - loss: 2.2987 - acc: 0.1162\n",
      "Epoch 2/45\n",
      "241/241 [==============================] - 7s 28ms/step - loss: 2.2990 - acc: 0.1154\n",
      "Epoch 3/45\n",
      "241/241 [==============================] - 7s 28ms/step - loss: 2.2990 - acc: 0.1112\n",
      "Epoch 4/45\n",
      "241/241 [==============================] - 7s 28ms/step - loss: 2.2981 - acc: 0.1220\n",
      "Epoch 5/45\n",
      "241/241 [==============================] - 7s 28ms/step - loss: 2.2995 - acc: 0.1187\n",
      "Epoch 6/45\n",
      "241/241 [==============================] - 7s 28ms/step - loss: 2.2978 - acc: 0.1154\n",
      "Epoch 7/45\n",
      "241/241 [==============================] - 7s 28ms/step - loss: 2.2977 - acc: 0.1162\n",
      "Epoch 8/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.3004 - acc: 0.1120\n",
      "Epoch 9/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.2989 - acc: 0.1162\n",
      "Epoch 10/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.2980 - acc: 0.1170\n",
      "Epoch 11/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.2971 - acc: 0.1162\n",
      "Epoch 12/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.3003 - acc: 0.1154\n",
      "Epoch 13/45\n",
      "241/241 [==============================] - 7s 28ms/step - loss: 2.2979 - acc: 0.1170\n",
      "Epoch 14/45\n",
      "241/241 [==============================] - 7s 28ms/step - loss: 2.2999 - acc: 0.1154\n",
      "Epoch 15/45\n",
      "241/241 [==============================] - 7s 28ms/step - loss: 2.2950 - acc: 0.1212\n",
      "Epoch 16/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.3024 - acc: 0.1095\n",
      "Epoch 17/45\n",
      "241/241 [==============================] - 7s 31ms/step - loss: 2.2981 - acc: 0.1170\n",
      "Epoch 18/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.2980 - acc: 0.1170\n",
      "Epoch 19/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.2976 - acc: 0.1178: 0s - loss: 2.2969 - acc: 0.\n",
      "Epoch 20/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.3002 - acc: 0.1154\n",
      "Epoch 21/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.3016 - acc: 0.1137\n",
      "Epoch 22/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.2939 - acc: 0.1195\n",
      "Epoch 23/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.2986 - acc: 0.1220\n",
      "Epoch 24/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.2992 - acc: 0.1145\n",
      "Epoch 25/45\n",
      "241/241 [==============================] - 7s 30ms/step - loss: 2.2969 - acc: 0.1104\n",
      "Epoch 26/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.2981 - acc: 0.1220\n",
      "Epoch 27/45\n",
      "241/241 [==============================] - 7s 30ms/step - loss: 2.2975 - acc: 0.1137\n",
      "Epoch 28/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.3006 - acc: 0.1129\n",
      "Epoch 29/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.2988 - acc: 0.1104\n",
      "Epoch 30/45\n",
      "241/241 [==============================] - 7s 30ms/step - loss: 2.2976 - acc: 0.1220: 0s - loss: 2.2978 - acc: 0.120\n",
      "Epoch 31/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.3032 - acc: 0.1145\n",
      "Epoch 32/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.2935 - acc: 0.1228\n",
      "Epoch 33/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.2988 - acc: 0.1129\n",
      "Epoch 34/45\n",
      "241/241 [==============================] - 7s 30ms/step - loss: 2.2972 - acc: 0.1154: 1s \n",
      "Epoch 35/45\n",
      "241/241 [==============================] - 7s 31ms/step - loss: 2.2945 - acc: 0.1212\n",
      "Epoch 36/45\n",
      "241/241 [==============================] - 7s 30ms/step - loss: 2.3023 - acc: 0.1170\n",
      "Epoch 37/45\n",
      "241/241 [==============================] - 7s 31ms/step - loss: 2.2982 - acc: 0.1095\n",
      "Epoch 38/45\n",
      "241/241 [==============================] - 8s 33ms/step - loss: 2.2966 - acc: 0.1245\n",
      "Epoch 39/45\n",
      "241/241 [==============================] - 7s 30ms/step - loss: 2.2996 - acc: 0.1178\n",
      "Epoch 40/45\n",
      "241/241 [==============================] - 7s 30ms/step - loss: 2.2986 - acc: 0.1120\n",
      "Epoch 41/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.3012 - acc: 0.1187\n",
      "Epoch 42/45\n",
      "241/241 [==============================] - 7s 29ms/step - loss: 2.2958 - acc: 0.1154\n",
      "Epoch 43/45\n",
      "241/241 [==============================] - 8s 31ms/step - loss: 2.2971 - acc: 0.1178\n",
      "Epoch 44/45\n",
      "241/241 [==============================] - 7s 31ms/step - loss: 2.2998 - acc: 0.1162\n",
      "Epoch 45/45\n",
      "241/241 [==============================] - 7s 30ms/step - loss: 2.2957 - acc: 0.1154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16f21bb1f28>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "steps_per_epoch = generator.n // params['batch_size']\n",
    "net.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "net.fit_generator(generator, steps_per_epoch=steps_per_epoch, epochs=params['num_epochs'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
